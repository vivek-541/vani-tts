# à¤µà¤¾à¤£à¥€ (Vani) TTS ğŸ™ï¸
### Lightweight Hindi Text-to-Speech for Consumer Devices

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Platform: Android | iOS | CPU](https://img.shields.io/badge/platform-Android%20%7C%20iOS%20%7C%20CPU-green.svg)]()
[![HuggingFace Dataset](https://img.shields.io/badge/dataset-ai4bharat%2Findicvoices__r-yellow.svg)](https://huggingface.co/datasets/ai4bharat/indicvoices_r)
[![Training: StyleTTS2](https://img.shields.io/badge/training-StyleTTS2-orange.svg)](https://github.com/yl4579/StyleTTS2)

> **à¤µà¤¾à¤£à¥€** (vÄá¹‡Ä«) â€” Sanskrit for *voice, speech, the goddess of language.*

Vani TTS is an open-source, on-device Hindi Text-to-Speech model trained using the **StyleTTS2** architecture, fine-tuned on the [AI4Bharat IndicVoices-R](https://huggingface.co/datasets/ai4bharat/indicvoices_r) dataset. It is designed to run in **real-time on CPU** â€” no internet, no GPU, no cloud â€” making it suitable for Android phones, iOS devices, and low-end laptops.

---

## ğŸŒ Why Vani?

| Model | Hindi Quality | On-Device | Mobile Ready | Open Source |
|---|---|---|---|---|
| Google TTS | âœ… Good | âŒ Cloud only | âŒ | âŒ |
| Veena (Maya Research) | âœ… Excellent | âŒ Needs GPU | âŒ | âŒ |
| AI4Bharat Indic Parler-TTS | âœ… Very Good | âŒ 0.9B params | âŒ | âœ… |
| Piper TTS (hi) | âš ï¸ Poor | âœ… | âœ… | âœ… |
| **Vani TTS** | âœ… **Goodâ†’Great** | âœ… **Yes** | âœ… **Yes** | âœ… **Yes** |

**Vani fills the gap: quality Hindi TTS that runs on your phone, offline, for free.**

---

## âœ¨ Features

- ğŸƒ **Real-time on CPU** â€” runs on any Android/iOS device
- ğŸ“´ **Fully offline** â€” no internet connection required
- ğŸ™ï¸ **Natural Hindi voice** â€” fine-tuned on 15,000 studio-grade Hindi speech samples
- ğŸ“¦ **ONNX export** â€” deploy on Android (ONNX Runtime) or iOS (CoreML)
- ğŸ”¡ **Devanagari native** â€” handles Hindi script directly via espeak-ng IPA phonemization
- âš–ï¸ **Lightweight** â€” target model size under 200MB

---

## ğŸ—‚ï¸ Project Structure

```
vani-tts/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ prepare_data.py         # Dataset streaming & preprocessing (IndicVoices-R)
â”œâ”€â”€ training/
â”‚   â””â”€â”€ StyleTTS2/              # StyleTTS2 fine-tuning repo (yl4579/StyleTTS2)
â”‚       â”œâ”€â”€ train_finetune.py   # Main training script
â”‚       â””â”€â”€ Configs/
â”‚           â””â”€â”€ config_ft.yml   # Vani training configuration
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ evaluate.py             # MOS, WER evaluation
â”œâ”€â”€ export/
â”‚   â”œâ”€â”€ export_onnx.py          # Export to ONNX
â”‚   â””â”€â”€ export_coreml.py        # Export to CoreML (iOS)
â”œâ”€â”€ android/                    # Android demo app (coming soon)
â”œâ”€â”€ ios/                        # iOS demo app (coming soon)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start (Inference â€” after model release)

> âš ï¸ Model weights not yet released â€” training in progress. Star the repo to get notified.

```bash
pip install vani-tts
```

```python
from vani import VaniTTS
tts = VaniTTS()
tts.synthesize("à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤®à¥‡à¤°à¤¾ à¤¨à¤¾à¤® à¤µà¤¾à¤£à¥€ à¤¹à¥ˆà¥¤", output="output.wav")
```

---

## ğŸ—ï¸ Architecture

Vani TTS is built on the **[StyleTTS2](https://github.com/yl4579/StyleTTS2)** architecture (the same backbone used by Kokoro-82M), fine-tuned from the LibriTTS pretrained checkpoint:

```
Devanagari Text â†’ espeak-ng (IPA phonemes) â†’ PLBERT â†’ Style Encoder â†’ HiFiGAN Decoder â†’ Audio
```

**Key architectural choices:**

- **StyleTTS2 over Piper** â€” StyleTTS2 uses adversarial style diffusion for naturalness vs Piper's 2021-era VITS; significantly better prosody and expressiveness ceiling
- **HiFiGAN decoder** â€” matches the LibriTTS pretrained base checkpoint; higher quality than iSTFT for fine-tuning from English pretrain
- **espeak-ng phonemizer** â€” handles Hindi IPA correctly via `phonemizer` library with `backend='espeak', language='hi'`; 49 unique Hindi phoneme tokens
- **Single speaker** â€” trained on a curated single-voice Hindi subset for maximum voice consistency
- **Why not larger models (Parler-TTS, Veena)?** At 0.9Bâ€“3B parameters, they require GPU inference and cannot run on mobile CPUs in real-time

---

## ğŸ“Š Dataset

| Property | Value |
|---|---|
| Source | [ai4bharat/indicvoices_r](https://huggingface.co/datasets/ai4bharat/indicvoices_r) |
| Language | Hindi (hi) |
| Sample Rate | 24,000 Hz |
| Training Samples | 14,250 |
| Validation Samples | 750 |
| Total Samples | 15,000 |
| Duration Filter | 1.0s â€“ 12.0s |
| Normalization | âˆ’20 dB RMS |
| Phoneme Tokens | 49 unique IPA tokens |
| Download Method | HF streaming + soundfile decode (no torchcodec required) |

---

## âš™ï¸ Training Configuration

| Parameter | Value |
|---|---|
| Base checkpoint | LibriTTS `epochs_2nd_00020.pth` (736MB) |
| Epochs | 50 |
| Batch size | 1â€“4 (GPU memory dependent) |
| Sample rate | 24,000 Hz |
| Decoder | HiFiGAN |
| Mixed precision | AMP fp16 |
| Hardware used | NVIDIA RTX 3060 12GB |
| Estimated training time | 48â€“72 hours |

---

## ğŸ“… Roadmap

- [x] Phase 0 â€” Environment setup (Ubuntu 24.04, CUDA 13.0, UV venv)
- [x] Phase 1 â€” Dataset pipeline (15k IndicVoices-R samples, 24kHz, âˆ’20dB RMS)
- [x] Phase 2 â€” Phonemization (espeak-ng IPA, 49 tokens, 14,250 train / 750 val)
- [x] Phase 3 â€” Pretrained weights + StyleTTS2 config (LibriTTS base, HiFiGAN decoder)
- [x] Phase 4 â€” Training loop stabilized (bug fixes: monotonic_align, mask_from_lens, AMP)
- [ ] **Phase 5 â€” 50 epochs training** â† ğŸ”„ IN PROGRESS
- [ ] Phase 6 â€” Evaluation (MOS score, WER via Whisper, RTF on CPU)
- [ ] Phase 7 â€” ONNX export (opset 17) + INT8 dynamic quantization
- [ ] Phase 8 â€” Android integration (ONNX Runtime)
- [ ] Phase 9 â€” iOS integration (CoreML)
- [ ] Phase 10 â€” pip package release + HuggingFace model upload
- [ ] Phase 11 â€” Multiple Hindi voices (male/female)
- [ ] Phase 12 â€” Hinglish support (code-switching)

---

## ğŸ“ˆ Evaluation Targets

| Metric | Target | Current |
|---|---|---|
| MOS Score | > 3.8 / 5.0 | ğŸ”„ Training |
| Word Error Rate (WER) | < 8% | ğŸ”„ Training |
| Real-Time Factor (CPU) | < 0.3x | ğŸ”„ Training |
| Model Size (quantized) | < 200 MB | ğŸ”„ Training |
| Android Latency | < 300ms/sec audio | ğŸ”„ Training |

---

## ğŸ› ï¸ Notable Engineering Decisions

| Problem | Solution |
|---|---|
| `torchcodec` missing in new datasets | `Audio(decode=False)` + manual soundfile decode |
| `misaki` has no Hindi module | `phonemizer` with `backend='espeak', language='hi'` |
| `monotonic_align` needs Cython compile | Pure Python fallback implementation |
| PyTorch 2.6 `weights_only` default changed | Added `weights_only=False` to all `torch.load` calls |
| LibriTTS checkpoint uses HiFiGAN not iSTFT | Set `decoder.type: hifigan` in config |
| RTX 3060 12GB VRAM with full StyleTTS2 | AMP fp16 + `batch_size=1` + `max_len=150` |

---

## ğŸ™ Acknowledgements

- [AI4Bharat](https://ai4bharat.iitm.ac.in/) for the IndicVoices-R dataset
- [yl4579](https://github.com/yl4579/StyleTTS2) for the StyleTTS2 training framework
- [hexgrad](https://huggingface.co/hexgrad/Kokoro-82M) for Kokoro-82M (inference pipeline)
- [StyleTTS2 paper](https://arxiv.org/abs/2306.07691) â€” Li et al., 2023
- [mychen76](https://huggingface.co/mychen76/styletts2) for ASR + JDC utility weights

---

## ğŸ“„ License

Apache 2.0 â€” free to use, modify, and deploy commercially.

---

## ğŸ¤ Contributing

Contributions welcome! If you speak Hindi natively and want to help evaluate naturalness (MOS scoring), please open an issue. Voice sample donations for future multi-speaker training also welcome.

---

*Built in Hyderabad ğŸ‡®ğŸ‡³ â€” making Hindi voice AI accessible to everyone, everywhere, offline.*
